\section{Problem 5.4.3} 
\contributor{Ngoc Tran}{ntran@math.utexas.edu}


\subsection{CSP background}
To make this exposition self-contained, we recall some materials from CSP. 
Let $x^\downarrow$ denote a sequence whose terms are non-increasing, that is, $x^\downarrow_1 \geq x^\downarrow_2 \geq \ldots$. Let $\mathcal{P}_{\cdot}$ stands for the set of partitions of $\cdot$. For instance, $\mathcal{P}_t = \{x = (x_1, x_2, \ldots), x_i \geq 0, \sum_ix_i = t\}$ are unordered partitions of the mass $t$, $\mathcal{P}_t^\downarrow = \{x^\downarrow: x \in \mathcal{P}_t\}$
is its ordered version. If $t \in [0,1]$, one can imagine breaking a chalk of mass 1 into countable many pieces, and record their sizes in some order. As we break up the chalk, infinitestimally small dust particles fall out, and $1-t$ is the total mass lost to dust. Write $\mathcal{P}_{[0,1]} = \bigcup_{t \in [0,1]} \mathcal{P}_t$ for the set of all possible chalk-mass sequences. Let $\mathcal{P}_{\mathbb{N}}$ denote partitions of $\mathbb{N}$, $PD(0,1)$ denote the Poisson-Dirichlet(0,1), which is a random distribution on $\mathcal{P}^\downarrow_1$, whose sequence is obtained by ranking the jumps of a $gamma(1)$ subordinator.

For a mass partition $x \in \mathcal{P}_1$, generate a sequence $U = (U_1, U_2, \ldots)$ of i.i.d uniform[0,1] random variables. Couple $x$ and $U$ to form $((x_i,U_i), i \geq 1)$, then rank the $U$-coordinate in increasing order. This puts $x$ is an \emph{exchangeable random order}. In general, for a distribution $P$ on $\mathcal{P}^\downarrow_{[0,1]}$, say that $X$ is an exchangeable $P$-partition of $[0,1]$ if a realization of $X$ is obtained by first drawing a $X^\downarrow \in \mathcal{P}_{[0,1]}^\downarrow$ according to $P$, then arrange this sequence in an exchangeable random order using a sequence of uniforms $U$ independent of $X^\downarrow$. For convenience, we will use $P$ to denote an ordered random mass partition, as well as its distribution. Let $P_0 := 1-\sum_{i\geq 1} P_i$ denote the dust mass. 

Let $X$ be an exchangeable $P$-partition of $[0,1]$. One can think of $X$ as a random measure as follows. Draw an ordered mass partition $P$.  For $U$ an i.i.d sequence of uniforms, independent of $P$, put mass $P_i$ at location $U_i$, plus $P_0$ times the Lebesgue measure
\begin{equation}\label{eqn:bridge}
b_P := \sum_iP_i \delta_{U_i} + (1-\sum_iP_i) \cdot \mbox{(Lebesgue-measure)}.
\end{equation}
Equation (\ref{eqn:bridge}) defines a $P$-bridge. Bridges form a convenient language for exchangeable coalescents. One can compose bridges as functions. One can check that composition of bridges are also bridges. In particular, for distributions $P,Q$ on $\mathcal{P}^\downarrow_{[0,1]}$, there exists a distribution $R$ on $\mathcal{P}^\downarrow_{[0,1]}$ such that
$$ b_R \stackrel{d}{=} b_P \circ b_Q. $$
Call $R$ the coagulation of $P$ by $Q$, denoted $Coag(P,Q)$, or $P(Q\mathsf{-Coag})$. 

The name suggests that masses in $P$ are merged according to $Q$. Indeed, here is a more general definition of coagulation. For $\pi \in \mathcal{P}_\mathbb{N}$, $s \in \mathcal{P}_{[0,1]}$, define the unordered coagulation of $s$ by $\Pi$ as the sequence
\begin{equation}\label{eqn:coag.u}
Coag(s,\pi) = (s_0|\pi_i| + \sum_{j \in \pi_i}s_j, i = 1,2,\ldots) \in \mathcal{P}_{[0,1]}.
\end{equation}
In other words, $\pi$ specifies which blocks to merge, $s_0$ is the size of the dust component of $s$, and this dust mass is sprinkled proportionally in each block. Note that the usual Coag operator in the literature is the ordered version $Coag^\downarrow(s,\pi) := (Coag(s,\pi))^\downarrow$. 

Now, suppose $S$ is an exchangeable $P$-partition, and $\Pi$ an independent partition of $\mathbb{N}$ such that $|\Pi|^\downarrow$ is a $Q$-partition. View $|\Pi|$ as an interval partition of $[0,1]$. Then $Coag(S,\Pi)$ groups together all masses of $S$ whose corresponding $U_i$'s fall in the same interval. One can check that $Coag^\downarrow(S,\Pi) \stackrel{d}{=} Coag^\downarrow(P,Q)$ (\cite[Lemma 5.18]{MR2245368}, \cite{MR2253162}). In other words, $Q$ specifies the sizes of the bins, and $P$ specifies the amount of mass to be sprinkled in each bin, with the dust distributed uniformly.

Finally, a word about ordered vs unordered Coag operator. Obviously if $\sigma$ is a permutation of $\mathbb{N}$, then
$$ Coag(S,\sigma\cdot\Pi) = \sigma \cdot Coag(S,\Pi). $$
One has the more subtle identity
$$ Coag(S,\mbox{SBP of } \Pi) \stackrel{d}{=} \mbox{SBP of } Coag(S, \Pi) \stackrel{d}{=} \mbox{SBP of } Coag^\downarrow(S, \Pi), $$
where SBP stands for size-biased permutation. In this formula, both the left and right hand side are random rearrangements of $Coag(S,\Pi)$. In the left hand side, bins with bigger mass with respect to $\Pi$ are more likely to be listed first. In the right hand side, bins with that contains bigger $S$-mass are more likely to be listed first. The point is that for an exchangeable mass partition $S$, in expectation, these masses are the same, hence the equality in distribution. 

\subsection{The problem}%a self-contained description of the problem
%Generalization of Theorem 5.21 to some other law $Q$. 

Identify $x \in \mathcal{P}$ with an interval partition of $[0,1]$, consisting of intervals of lengths $x_1, x_2, \ldots$, listed from left to right. Let $d$ be its set of divider points (that is, the interval partition is the union of disjoint intervals in $[0,1] \backslash d$). 
%View a mass partition $x$ with $\sum_ix_i = 1$ as an interval partition of $[0,1]$; let $d_1, d_2, \ldots$ be the sequence of right-end points on this interval partition. 
The $D$-partition derived from $x$ is the interval partition $x^D = (x^D_1, x^D_2, \ldots)$, obtained from $x$ by the following construction:
\begin{itemize}
  \item Throw a ball uniformly at $[0,1]$. Say it lands at $V_1$. Look to the right of $V_1$, let $d(V_1)$ be the first point in $d$ encountered. 
  \item Define $I^D_1 = [0,d(V_1)]$. Repeat this game on the remaining interval partition on $[d(V_1), 1]$. 
\end{itemize}
Note that an interval of $x^D$ is obtained by joining a random number of the intervals of $x$. We ask: when is $x^D$ a coagulation of $x$?

Now suppose $X$ is an exchangeable $P$-partition of $[0,1]$. Therem 5.21 in \cite{MR2245368} spells out the law of $X^D$ as a function of $P$. 

\begin{theorem}[\cite{MR2245368}, Theorem 5.21]\label{thm:5.21}
Let $X$ be an exchangeable $P$-partition of $[0,1]$. Then $X^D$ is the size-biased permutation of a $R$-partition of $[0,1]$, where $R = Coag^\downarrow(P,PD(0,1))$. 
\end{theorem}

This theorem supplies a nice description of the map $P \mapsto Coag^\downarrow(P,PD(0,1))$ operator in terms of the $D$-partition. The problem is: is there a similar description for the map $P \mapsto Coag^\downarrow(P,PD(\alpha,\theta))$? 

\subsection{Literature review} %put a mini review of the problem: for example, motivations, current status, thoughts, ...  

Here, $D$ stands for \emph{droite}.
The D-partition was first defined by Aldous and Pitman \cite{MR1293075}, when $P$ is the partition defined by excursions of a standard Brownian bridge. This is reviewed in \cite[\S 9]{MR2245368}, where the D-partition features in \cite[Theorem 9.6]{MR2245368}. Independent of this application, creating coagulation by sampling, then `rounding' by taking the right-end point, is quite a natural operation. 
Theorem 5.21 is an extract from \cite[Theorem 23]{MR2276901}, where the authors consider various properties of $D$-partition derived from Brownian bridges, realize that the result hold for general exchangeable mass partition $P$. 

\subsection{Thoughts} %thoughts, computations that you are willing to share

First we need to generalize the definition of the $D$-partition. A natural generalization is to keep the stick-breaking-then-rounding construction, but do not require the stick breaks $V_i$'s be i.i.d uniform. 

\begin{definition}
Let $F$ be a distribution on $[0,1]$. A $D$-partition with weight $F$ derived from $x$ is the interval partition $x^{D(F)}$, obtained from $x$ by the following construction: 
\begin{itemize}
  \item Throw a ball on $[0,1]$ according to $F$. Say it lands at $V_1$. Look to the right of $V_1$, let $d(V_1)$ be the first point in $d$ encountered. 
  \item Define $I^D_1 = [0,d(V_1)]$. Repeat this game on the remaining interval partition on $[d(V_1), 1]$. 
\end{itemize}
\end{definition}
The usual $D$-partition corresponds to one with uniform weight. Now, we can translate the problem as:

\textbf{Problem.} Let $X$ be an exchangeable $P$-partition of $[0,1]$. For what distributions $F$ is $(X^{D(F)}) \stackrel{d}{=} Coag(P, Q)$ for some $Q$? We require that neither $F$ nor $Q$ depend on $P$. 

One such pair $(F,Q)$ is (uniform,$PD(0,1)$). The following result says that this is the only pair.

\begin{theorem}\label{thm:543}
Suppose $X^{D(F)} \stackrel{d}{=} Coag(P, Q)$ for some $Q$. Then $F$ must be the uniform distribution, in which case $Q = PD(0,1)$. 
\end{theorem}

Since $F$ and $Q$ cannot depend on $P$, it is sufficient to prove this statement for fixed $P = p$. However, we will write $b_P$ with capital $P$, to remind us that there is randomness in the construction of the bridge.

Our proof relies on the following description of the first term of the sequence $X^{D(F)}$. The proof is a definition chase (draw a picture), and note that $b_P$ and $b_P^{-1}$ are both right-continuous. 

\begin{lemma}
Fix $P$. Let $b_P$ be a bridge based on $P$, $b_P^{-1}$ be its right-continuous inverse. Let $X = (X_1, X_2, \ldots)$ be the sequence of jumps of $b_P$. Then 
\begin{equation}\label{eqn:df1}
X^{D(F)}_1 = b_P(b_P^{-1}(V_1)),
\end{equation}
where $V_1 \sim F$ is independent of $X$. %Furthermore, condition on $X^{D(F)}_1 = y_1$, let $P^{(1)}(y_1)$ be the remaining partition of $[0,1-y_1]$ scaled by $\frac{1}{1-y_1}$, and 
%so that it is an exchangeable partition of $[0,1]$. Then 
%$$(X^{D(F)}_2|X^{D(F)}_1 = y_1) = b_{P^{(1)}(y_1)}(b_{P^{(1)}(y_1)}^{-1}(V_2))$$
%for $V_2 \sim F$, independent of $V_1$ and $b_{P^{(1)}(y_1)}$. 
\end{lemma}

\begin{example}
Suppose $F = Uniform[0,1]$. By Bertoin and Le Gall \cite{MR1990057}, $b_P^{-1}(V_1)$ is uniform. For $Q = PD(0,1)$, its size-biased permutation $\tilde{Q}$ is the $GEM(0,1)$, which has the i.i.d uniform stick-breaking representation. In particular, 
$$ (\mbox{SBP of } Coag^\downarrow(P,Q))_1 \stackrel{d}{=} Coag^\downarrow(P,\tilde{Q}))_1 \stackrel{d}{=} b_P(U_1), $$
where $U_1$ is uniform. So at least we have an equality in distribution
$$ b_P(U_1) \stackrel{d}{=} b_P(b_P^{-1}(V_1)). $$
In fact, Bertoin and Le Gall's lemma and the i.i.d uniform stick-breaking representation of $GEM(0,1)$ can be used recursively to prove~Theorem \ref{thm:5.21}. This is different(?) from the combinatorial argument originally presented in \cite{MR2245368}.
\end{example}

\begin{proof}[Proof of Theorem \ref{thm:543}] 
Suppose $X^{D(F)} \stackrel{d}{=} Coag(P, Q)$. Then the first term of the two sequences must have the same distribution
$$X^{D(F)}_1 \stackrel{d}{=} b_P(b_P^{-1}(V_1)) \stackrel{d}{=} Coag(P, Q)_1 \stackrel{d}{=} b_P(Q_1).$$ 
Thus one must have 
$$b_P^{-1}(V_1) \stackrel{d}{=} Q_1,$$ 
where $V_1 \sim F$, and $Q_1$ is some random variable with distribution $F_Q$, taking values in $[0,1]$. This equality must holds for all $P$. Now consider a simple distribution $P$ with $P^\downarrow = (s, 0, 0, \ldots)$, where $s \in (0,1)$. Then $b_P^{-1}(V_1)$ is a mixture of $s$ times the uniform distribution, plus $(1-s)$ times some other distribution. Thus, $F_Q(t)$ must have mass at least $s \cdot t$, and one can choose $s$ arbitrarily close to $1$. Thus, $F_Q$ must be the uniform distribution, in which case $F$, the distribution of $V_1$, must also be uniform. 
\end{proof}

%What if taking the left-end point instead? (anti-size-biased...?)




