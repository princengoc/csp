\section{Problem 5.4.3} 
\contributor{Ngoc Tran}{ntran@math.utexas.edu}


\subsection{CSP background}
To make this exposition self-contained, we recall some materials from CSP. 
Let $x^\downarrow$ denote a sequence whose terms are non-increasing, that is, $x^\downarrow_1 \geq x^\downarrow_2 \geq \ldots$. Let $\mathcal{P}_1 = \{x = (x_1, x_2, \ldots), x_i \geq 0, \sum_ix_i = 1\}$ be the space of conservative mass partitions, $\mathcal{P}_1^\downarrow = \{x^\downarrow: x \in \mathcal{P}_1\}$ be the space of ordered, conservative mass partitions. Let $PD(0,1)$ denote the Poisson-Dirichlet(0,1), which is a random distribution on $\mathcal{P}^\downarrow_1$, whose sequence is obtained by ranking the jumps of a $gamma(1)$ subordinator.

\subsubsection{Exchangeable mass partitions}

Suppose that $X$ is a a random variable taking values in $\mathcal{P}_1$, that is, a random mass partition. Say that $X$ is exchangeable if as a sequence of random variables $(X_1, X_2, \ldots)$, it is exchangeable (ie: the joint law is invariant under permutations). The law of an exchangeable random mass partition is defined by a probability distribution on $\mathcal{P}_1^\downarrow$. For example, if $X$ is an exchangeable $P$-partition of $[0,1]$, then a realization of $X$ is obtained by first drawing a mass partition $x^\downarrow \in \mathcal{P}_1^\downarrow$ according to distribution $P$, then arrange this sequence in an exchangeable random order. 

\subsubsection{Exchangeable coagulation and bridges}
Now we recall the coagulation operator for an exchangeable mass coalescent. Let $Q$ be a distribution on $\mathcal{P}^\downarrow_1$. Let $\Pi$ be a partition of $\mathbb{N}$ obtained by the Kingman's paintbox based on $Q$. For $s \in \mathcal{P}_{[0,1]}$, the coagulation of $s$ by $\Pi$ is the mass partition defined as
\begin{equation}\label{eqn:coag}
Coag(s,\Pi) = (s_0|\Pi_i| + \sum_{j \in \Pi_i}s_j, i = 1,2,\ldots)^\downarrow, 
\end{equation}
where $|\Pi_i|$ is the asymptotic frequency of the $i$-th block of $\Pi$, and $s_0 = 1-\sum_{j=1}^\infty s_j$. In other words, $\Pi$ specifies which blocks to merge, $s_0$ is the size of the dust component of $s$, and this dust mass is sprinkled proportionally in each block. 

In what follows, for convenience, we define the unranked version of the $Coag$ operator
\begin{equation}\label{eqn:coag.u}
Coag^u(s,\Pi) = (s_0|\Pi_i| + \sum_{j \in \Pi_i}s_j, i = 1,2,\ldots). 
\end{equation}
Obviously if $\sigma$ is a permutation of $\mathbb{N}$, then
$$ Coag^u(S,\sigma\cdot\Pi) = \sigma \cdot Coag^u(S,\Pi). $$
One has the more subtle identity
$$ Coag^u(S,\mbox{SBP of } \Pi) \stackrel{d}{=} \mbox{SBP of } Coag(S, \Pi), $$
where SBP stands for size-biased permutation. In this formula, both the left and right hand side are random rearrangements of $Coag(S,\Pi)$. In the left hand side, bins with bigger mass with respect to $\Pi$ are more likely to be listed first. In the right hand side, bins with that contains bigger $S$-mass are more likely to be listed first. The point is that for an exchangeable mass partition $S$, in expectation, these masses are the same, hence the equality in distribution. 

Let $S$ be an exchangeable $P$-partition. Clearly $Coag(S,\Pi)$ only depends on $P$ and $Q$. We call this the coagulation of $P$ by $Q$, denoted $Coag(P,Q)$, or $P(Q\mathsf{-Coag})$. One can state $Coag(S, \Pi)$ in terms of $P$ and $Q$ only. Let $U_i \sim U[0,1]$ be an i.i.d sequence of uniforms, independent of $S$. Consider the random measure which puts mass $S_i^\downarrow = P_i$ at location $U_i$, plus $S_0$ times the Lebesgue measure
\begin{equation}\label{eqn:bridge}
b_P := \sum_iP_i \delta_{U_i} + (1-\sum_iP_i) \cdot \mbox{(Lebesgue-measure)}.
\end{equation}
Now let $X$ be an exchangeable $Q$-partition. View $X$ as an exchangeable interval partition of $[0,1]$. Group together all masses of $\tau$ whose corresponding $U_i$'s fall in the same interval, then rank this sequence. In other words, $Q$ specifies the sizes of the bins, and $P$ specifies the amount of mass to be sprinkled in each bin, with the dust distributed uniformly. 

Thinking about exchangeable mass partitions as random measures as in (\ref{eqn:bridge}) is quite beneficial. Equation (\ref{eqn:bridge}) defines a $P$-bridge. Similarly, one can define a $Q$-bridge. One can view a bridge as a function from $[0,1]$ to $[0,1]$. Compositions of a bridge is still a bridge. We have \cite[Lemma 5.18]{CSP}, \cite[Lemma XXX]{Bertoin}
$$ b_P \circ b_Q = b_{Coag(P,Q)}. $$
This description reveals a symmetry between $Coag(P,Q)$ and $Coag(Q,P)$. 

\subsection{The problem}%a self-contained description of the problem
%Generalization of Theorem 5.21 to some other law $Q$. 

Identify $x \in \mathcal{P}$ with an interval partition of $[0,1]$, consisting of intervals of lengths $x_1, x_2, \ldots$, listed from left to right. Let $d$ be its set of divider points (that is, the interval partition is the union of disjoint intervals in $[0,1] \backslash d$). 
%View a mass partition $x$ with $\sum_ix_i = 1$ as an interval partition of $[0,1]$; let $d_1, d_2, \ldots$ be the sequence of right-end points on this interval partition. 
The $D$-partition derived from $x$ is the interval partition $x^D = (x^D_1, x^D_2, \ldots)$, obtained from $x$ by the following construction:
\begin{itemize}
  \item Throw a ball uniformly at $[0,1]$. Say it lands at $V_1$. Look to the right of $V_1$, let $d(V_1)$ be the first point in $d$ encountered. 
  \item Define $I^D_1 = [0,d(V_1)]$. Repeat this game on the remaining interval partition on $[d(V_1), 1]$. 
\end{itemize}
Note that an interval of $x^D$ is obtained by joining a random number of the intervals of $x$. We ask: when is $x^D$ a coagulation of $x$?

Now suppose $X$ is an exchangeable $P$-partition of $[0,1]$. Therem 5.21 spells out the law of $X^D$ as a function of $P$. 

\begin{theorem}[\cite{csp}, Theorem 5.21]\label{thm:5.21}
Let $X$ be an exchangeable $P$-partition of $[0,1]$. Then $X^D$ is the size-biased permutation of a $R$-partition of $[0,1]$, where $R = Coag(P,PD(0,1))$. 
\end{theorem}

This theorem supplies a nice description of the map $P \mapsto Coag(P,PD(0,1))$ operator in terms of the $D$-partition. The problem is: is there a similar description for the map $P \mapsto Coag(P,PD(\alpha,\theta))$? 

\subsection{Literature review} %put a mini review of the problem: for example, motivations, current status, thoughts, ...  

Here, $D$ stands for \emph{droite}. Creating coagulation by sampling, then `rounding' by taking the right-end point, is quite a natural operation when one considers partitions defined by excursions of a standard Brownian bridge. (TODO: review csp17). Theorem 5.21 came out of \cite{csp24}. (TODO: review csp24). 
TODO: google search D-partitions (not found anything)
TODO: search papers that cite the above references.

\subsection{Thoughts} %thoughts, computations that you are willing to share

First we need to generalize the definition of the $D$-partition. A natural generalization is to keep the stick-breaking-then-rounding construction, but do not require the stick breaks $V_i$'s be i.i.d uniform. 

\begin{definition}
Let $F$ be a distribution on $[0,1]$. A $D$-partition with weight $F$ derived from $x$ is the interval partition $x^{D(F)}$, obtained from $x$ by the following construction: 
\begin{itemize}
  \item Throw a ball on $[0,1]$ according to $F$. Say it lands at $V_1$. Look to the right of $V_1$, let $d(V_1)$ be the first point in $d$ encountered. 
  \item Define $I^D_1 = [0,d(V_1)]$. Repeat this game on the remaining interval partition on $[d(V_1), 1]$. 
\end{itemize}
\end{definition}
The usual $D$-partition corresponds to one with uniform weight. Now, we can translate the problem as:

\textbf{Problem.} Let $X$ be an exchangeable $P$-partition of $[0,1]$. For what distributions $F$ is $(X^{D(F)}) \stackrel{d}{=} Coag^u(P, Q)$ for some $Q$? We require that neither $F$ nor $Q$ depend on $P$. 

One such pair $(F,Q)$ is (uniform,$PD(0,1)$). The following result says that this is the only pair.

\begin{theorem}\label{thm:543}
Suppose $X^{D(F)} \stackrel{d}{=} Coag^u(P, Q)$ for some $Q$. Then $F$ must be the uniform distribution, in which case $Q = PD(0,1)$. 
\end{theorem}

Since $F$ and $Q$ cannot depend on $P$, it is sufficient to prove this statement for fixed $P = p$. However, we will write $b_P$ with capital $P$, to remind us that there is randomness in the construction of the bridge.

Our proof relies on the following description of the first term of the sequence $X^{D(F)}$. The proof is a definition chase (draw a picture), and note that $b_P$ and $b_P^{-1}$ are both right-continuous. 

\begin{lemma}
Fix $P$. Let $b_P$ be a bridge based on $P$, $b_P^{-1}$ be its right-continuous inverse. Let $X = (X_1, X_2, \ldots)$ be the sequence of jumps of $b_P$. Then 
\begin{equation}\label{eqn:df1}
X^{D(F)}_1 = b_P(b_P^{-1}(V_1)),
\end{equation}
where $V_1 \sim F$ is independent of $X$. %Furthermore, condition on $X^{D(F)}_1 = y_1$, let $P^{(1)}(y_1)$ be the remaining partition of $[0,1-y_1]$ scaled by $\frac{1}{1-y_1}$, and 
%so that it is an exchangeable partition of $[0,1]$. Then 
%$$(X^{D(F)}_2|X^{D(F)}_1 = y_1) = b_{P^{(1)}(y_1)}(b_{P^{(1)}(y_1)}^{-1}(V_2))$$
%for $V_2 \sim F$, independent of $V_1$ and $b_{P^{(1)}(y_1)}$. 
\end{lemma}

\begin{example}
Suppose $F = Uniform[0,1]$. By Bertoin and Le Gall \cite{bertoin44}, $b_P^{-1}(V_1)$ is uniform. For $Q = PD(0,1)$, its size-biased permutation $\tilde{Q}$ is the $GEM(0,1)$, which has the i.i.d uniform stick-breaking representation. In particular, 
$$ (\mbox{SBP of } Coag(P,Q))_1 \stackrel{d}{=} Coag(P,\tilde{Q}))_1 \stackrel{d}{=} b_P(U_1), $$
where $U_1$ is uniform. So at least we have an equality in distribution
$$ b_P(U_1) \stackrel{d}{=} b_P(b_P^{-1}(V_1)). $$
In fact, Bertoin and Le Gall's lemma and the i.i.d uniform stick-breaking representation of $GEM(0,1)$ can be used recursively to prove~Theorem \ref{thm:5.21}.
\end{example}

\begin{proof}[Proof of Theorem \ref{thm:543}] 
Suppose $X^{D(F)} \stackrel{d}{=} Coag^u(P, Q)$. Then the first term of the two sequences must have the same distribution
$$X^{D(F)}_1 \stackrel{d}{=} b_P(b_P^{-1}(V_1)) \stackrel{d}{=} Coag^u(P, Q)_1 \stackrel{d}{=} b_P(Q_1).$$ 
Thus one must have 
$$b_P^{-1}(V_1) \stackrel{d}{=} Q_1,$$ 
where $V_1 \sim F$, and $Q_1$ is some random variable with distribution $F_Q$, taking values in $[0,1]$. This equality must holds for all $P$. Now consider a simple distribution $P$ with $P^\downarrow = (s, 0, 0, \ldots)$, where $s \in (0,1)$. Then $b_P^{-1}(V_1)$ is a mixture of $s$ times the uniform distribution, plus $(1-s)$ times some other distribution. Thus, $F_Q(t)$ must have mass at least $s \cdot t$, and one can choose $s$ arbitrarily close to $1$. Thus, $F_Q$ must be the uniform distribution, in which case $F$, the distribution of $V_1$, must also be uniform. 
\end{proof}

%What if taking the left-end point instead? (anti-size-biased...?)




